{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import pickle\n",
    "import nltk\n",
    "from time import time\n",
    "from sklearn.utils import shuffle\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "done in 0.346s.\n"
     ]
    }
   ],
   "source": [
    "# read table into dataframe\n",
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "with open('03_tokentext_en.pickle', 'rb') as handle:\n",
    "    trade_war_tokentext = pickle.load(handle)\n",
    "dataset = trade_war_tokentext\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "n_features = 2000\n",
    "n_components = 5\n",
    "n_top_words = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stopwords\n",
    "depun_gen_stop = [i.replace(\"'\",\"\") for i in stopwords.words('english')]\n",
    "general_stopwords = list(set(stopwords.words('english') + depun_gen_stop))\n",
    "\n",
    "web_stopwords = ['html','via','youtube','rt','twitter','tweet','tweets']\n",
    "domain_stopwords = ['donald','trade','war','tradewar',\n",
    "                    'realdonaldtrump','trump','trumps','dtj','djt','president','america','american']\n",
    "media_stopwords = ['nyt','reuters','video','news','bloomberg','wsj','cnn','medium',\n",
    "                   'newspaper','insider']\n",
    "gabage_stopwords = ['g','doesnt','e','he','youre','dont','thats','could',\n",
    "                    'really','would','may','much','many','everything','any',\n",
    "                    'get','everyone','going','one','nobody','cant','nothing','lot','think','know',\n",
    "                    'make','go','warhtml','say','day','week','look','said','want','plan','set','time',\n",
    "                    'need','see','way','year','thing','people','move','state','take']\n",
    "\n",
    "stop_words = general_stopwords + web_stopwords + domain_stopwords + media_stopwords + gabage_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for NMF...\n",
      "done in 11.903s.\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# tokenization and modeling\n",
    "\n",
    "# Use tf-idf features for NMF.\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.4,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words=stop_words)\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(dataset)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print('--------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting the NMF model (Frobenius norm) with tf-idf features, n_components=5...\n",
      "done in 34.357s.\n",
      "\n",
      "Topics in NMF model (Frobenius norm):\n",
      "Topic #0: china hold talk lose fight winning beijing business escalates history\n",
      "Topic #1: tariff steel good eu import hit escalates aluminum canada threatens\n",
      "Topic #2: fear stock market dow point street fall share investor ease\n",
      "Topic #3: win pompeo canada weapon eu country help lose imf reason\n",
      "Topic #4: farmer economy hurt started world start job country business soybean\n",
      "\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (Frobenius norm) with tf-idf features, \"\n",
    "      \"n_components=%d...\"\n",
    "      % n_components)\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model (Frobenius norm):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)\n",
    "print('--------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get two metrices\n",
    "\n",
    "doc_topic = nmf.transform(tfidf)\n",
    "topic_word = nmf.components_\n",
    "\n",
    "df_doc_topic = pd.DataFrame(doc_topic)\n",
    "df_topic_word = pd.DataFrame(topic_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load df\n",
    "\n",
    "with open('02_df_en.pickle', 'rb') as handle:\n",
    "    df = pickle.load(handle)\n",
    "    \n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out each document's topic, filter out gabage\n",
    "\n",
    "def assign_topic(indx):\n",
    "    if doc_topic[indx].sum() == 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return np.argmax(doc_topic[indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign topics and filter out gabage\n",
    "\n",
    "df['topic'] = [assign_topic(i) for i in df.index]\n",
    "df = df[df['topic']!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign topic3 to topic1, topic4 to topic3\n",
    "\n",
    "def change_topic(i):\n",
    "    if i == 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return i\n",
    "\n",
    "def change_topic2(i):\n",
    "    if i == 4:\n",
    "        return 3\n",
    "    else:\n",
    "        return i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topic'] = df['topic'].apply(change_topic)\n",
    "df['topic'] = df['topic'].apply(change_topic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map topic names\n",
    "mapp = {0:'China & Fight',\n",
    "        1:'Tariff & EU, Canada',\n",
    "        2:'Stock Maket',\n",
    "        3:'Farmer & Economy & Job'}\n",
    "\n",
    "def map_name(num):\n",
    "    return mapp[num]\n",
    "\n",
    "df['topic_name'] = df['topic'].apply(map_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>text</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WineTasteAddict</td>\n",
       "      <td>2018-03-30 19:57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>trumps trade war with china could hurt califor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>979870258382110721</td>\n",
       "      <td>https://twitter.com/WineTasteAddict/status/979...</td>\n",
       "      <td>0</td>\n",
       "      <td>China &amp; Fight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WineTasteAddict</td>\n",
       "      <td>2018-03-30 19:57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>trumps trade war with china could hurt califor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>979870182263918592</td>\n",
       "      <td>https://twitter.com/WineTasteAddict/status/979...</td>\n",
       "      <td>0</td>\n",
       "      <td>China &amp; Fight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chrischandler</td>\n",
       "      <td>2018-03-30 19:51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>how to win a trade war</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>979868626240012288</td>\n",
       "      <td>https://twitter.com/chrischandler/status/97986...</td>\n",
       "      <td>1</td>\n",
       "      <td>Tariff &amp; EU, Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BcabaNetwork</td>\n",
       "      <td>2018-03-30 19:47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>asias small open economies may suffer in ameri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>979867757767426048</td>\n",
       "      <td>https://twitter.com/BcabaNetwork/status/979867...</td>\n",
       "      <td>3</td>\n",
       "      <td>Farmer &amp; Economy &amp; Job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CharmCity2052</td>\n",
       "      <td>2018-03-30 19:44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>china owns more of our debt than any country i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>979867078860689410</td>\n",
       "      <td>https://twitter.com/CharmCity2052/status/97986...</td>\n",
       "      <td>0</td>\n",
       "      <td>China &amp; Fight</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username              date  retweets  favorites  \\\n",
       "0  WineTasteAddict  2018-03-30 19:57         0          0   \n",
       "1  WineTasteAddict  2018-03-30 19:57         0          0   \n",
       "2    chrischandler  2018-03-30 19:51         0          0   \n",
       "3     BcabaNetwork  2018-03-30 19:47         0          0   \n",
       "4    CharmCity2052  2018-03-30 19:44         0          0   \n",
       "\n",
       "                                                text mentions hashtags  \\\n",
       "0  trumps trade war with china could hurt califor...      NaN      NaN   \n",
       "1  trumps trade war with china could hurt califor...      NaN      NaN   \n",
       "2                            how to win a trade war       NaN      NaN   \n",
       "3  asias small open economies may suffer in ameri...      NaN      NaN   \n",
       "4  china owns more of our debt than any country i...      NaN      NaN   \n",
       "\n",
       "                   id                                          permalink  \\\n",
       "0  979870258382110721  https://twitter.com/WineTasteAddict/status/979...   \n",
       "1  979870182263918592  https://twitter.com/WineTasteAddict/status/979...   \n",
       "2  979868626240012288  https://twitter.com/chrischandler/status/97986...   \n",
       "3  979867757767426048  https://twitter.com/BcabaNetwork/status/979867...   \n",
       "4  979867078860689410  https://twitter.com/CharmCity2052/status/97986...   \n",
       "\n",
       "   topic              topic_name  \n",
       "0      0           China & Fight  \n",
       "1      0           China & Fight  \n",
       "2      1     Tariff & EU, Canada  \n",
       "3      3  Farmer & Economy & Job  \n",
       "4      0           China & Fight  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickling\n",
    "\n",
    "with open('04_df_en.pickle', 'wb') as handle:\n",
    "    pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca plot\n",
    "\n",
    "temp = df[['username','topic']]\n",
    "temp = (temp.join(pd.DataFrame(tfidf.toarray()))\n",
    "                        .drop('username',axis=1))\n",
    "\n",
    "#y = temp['topic']\n",
    "X = temp.drop('topic',axis=1)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 2)\n",
    "PCAxy = pca.fit_transform(X)\n",
    "\n",
    "# plt.figure(figsize = (16,12))\n",
    "# plt.scatter(x[:,0], x[:,1], c=y)\n",
    "# plt.show()\n",
    "\n",
    "# plot data with seaborn\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['x']=PCAxy.T[0]\n",
    "data['y']=PCAxy.T[1]\n",
    "data['labels']=list(temp['topic'])\n",
    "\n",
    "facet = sns.lmplot(data=data, x='x', y='y', hue='labels', \n",
    "                   fit_reg=False, legend=True, legend_out=True, size=12, aspect=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique user names for location scraping\n",
    "\n",
    "users = df['username'].unique()\n",
    "with open('users.pickle', 'wb') as handle:\n",
    "    pickle.dump(users, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the most retweeted users top 1000\n",
    "\n",
    "# top_re_users = (df.groupby('username',as_index=False).agg({'retweets':sum})\n",
    "#                                 .sort_values(by='retweets',ascending=False)\n",
    "#                                 .head(1000)['username'].tolist())\n",
    "# # pickling\n",
    "\n",
    "# with open('top_re_users.pickle', 'wb') as handle:\n",
    "#     pickle.dump(top_re_users, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
